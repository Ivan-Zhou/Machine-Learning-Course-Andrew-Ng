{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Spam Classifier\n",
    "Supervised Learning\n",
    "- $x$: features of email - 100 words indicative of spam/not spam\n",
    "    - Check whether or not the words appear in the email\n",
    "        - 1 if appear, and 0 if not\n",
    "    - IN practice, take most frequently occuring $n$ words (10K - 50K)\n",
    "- $y$: If the email is spam (1) or not (0)\n",
    "\n",
    "### Implementation\n",
    "- Collect lots of data\n",
    "- Develop sophisticated features based on email routing information (from email header)\n",
    "- Develop sophisticated features for message body\n",
    "- Develop sophisticated algorithm to detect misspellings\n",
    "    - Otherwise we cannot recognize misspelled words that should be regarded as \"spam\"\n",
    "    - Spam emails may use intended typo to cheat the spam classifiers\n",
    "    \n",
    "## Good Practice\n",
    "- Start with a simple algorithm that you can implement quickly (24 hrs). Implement and test it on your cross-validation data\n",
    "    - Quick and dirty\n",
    "- **Plot learning curves** to decide if more data, more features, etc are likely to help\n",
    "- **Error Analysis**: manually examine the examples in the cross-validation set that your algorithm made errors on\n",
    "    - See if you can identify any systematic trend/pattern in what type of examples it is making errors on\n",
    "    - For example, in email misclassification, identify \n",
    "        - What are the major types of emails that got misclassified\n",
    "        - What features you think would have helped the algorithm classify them correctly\n",
    "            - Deliberate misspelling, unusual email routing, unusual punctuation\n",
    "- **Numerical Evaluation of your learning algorithm**: help you make quick selection and evaluate the improvement of your learning algorithm\n",
    "    - Accuracy, precision, Cross Validation Error, etc\n",
    "\n",
    "## Skewed Classes\n",
    "Skewed classes: our target classes that are rare in the sample data, so the cost of misclassification is very low to the algorithm\n",
    "- We can get a high accuracy metric by doing nothing\n",
    "- We cannot rely on the traditional error/accuracy metrics\n",
    "\n",
    "### Error Metrics of the Skewed Classes\n",
    "- Precision: of all the patients where we give positive prediction, what **fraction** is actually **True Positive**\n",
    "- Recall: of all the patients who actually have cancer, what **fraction** did we correctly **predict as Positive**\n",
    "\n",
    "#### Tradeoff\n",
    "- If you use a **higher threshold** (like 0.7 instead of 0.5), your positive prediction will require a higher confidence -- Result: **Higher Precision & Lower Recall**\n",
    "- If we want to **avoid missing too many cases of cancer** (false negatives), you set a low threshold -- result: **Lower Precision & Higher Recall**\n",
    "\n",
    "![W6-PRTRADEOFF](Plots/W6-PRTRADEOFF.png)\n",
    "\n",
    "#### F score: Compare Precision & Recall \n",
    "- $F_1 = 2*\\frac{PR}{P+R}$\n",
    "    - The higher, the better\n",
    "- Simply compute the average of Precision and Recall: $\\frac{P+R}{2}$ is not desirable\n",
    "    - Usually force one metric to become very high as a cost\n",
    "    \n",
    "## Use Large Data Sets\n",
    "### Rationale\n",
    "- First, use a learning algorithm with **many parameteres**: $J_{train}(\\theta)$ will be small and bias will be low (avoid underfitting)\n",
    "- Second, use a very large training set: $J_{train}(\\theta) \\approx J_{test}(\\theta)$ and variance will be low (avoid overfitting)\n",
    "- Result: $J_{test}(\\theta)$ will be small"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
